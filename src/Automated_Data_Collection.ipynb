{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "4aHoI4oOoJ8R"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import plotly\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import MySQLdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVOnztDkoShE"
   },
   "source": [
    "1.) CSV containing games from 2015+ (1 for all stats)\n",
    "2.) CSV with all player stats by season\n",
    "3.) CSV with all team stats by season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHhFaildoSod"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iUWBJ9--qEyg"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2pRlF2dKKmH"
   },
   "source": [
    "# Creating CSV with all games from 2015+"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V7o_bNgRKKmJ"
   },
   "source": [
    "Scraping team data from 2015 and later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MpPAtNtFPnIN"
   },
   "outputs": [],
   "source": [
    "def date_to_str(date):\n",
    "  '''\n",
    "  Args:\n",
    "        date (datetime): datetime object for the day of the season\n",
    "\n",
    "  Returns:\n",
    "        str: string representation of the given date\n",
    "\n",
    "  '''\n",
    "  month = str(date.month)\n",
    "  day = str(date.day)\n",
    "  if date.day <= 9:\n",
    "    day = str(0) + day\n",
    "  if date.month <= 9:\n",
    "    month = str(0) + month\n",
    "  return str(date.year) + '-' + month + '-' + day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0jcChFV-GWf"
   },
   "source": [
    "Scraping process takes ~20 minutes; CSV stored for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJAClzs3NolC"
   },
   "outputs": [],
   "source": [
    "def collect_team_data():\n",
    "  '''\n",
    "    Scrapes FanGraphs data from each day between April 1, 2015 and today's date\n",
    "\n",
    "    Returns:\n",
    "        hit (pd.DataFrame) contains hitting stats with each record representing one game for a team\n",
    "        pit (pd.DataFrame) contains pitching stats with each record representing one game for a team\n",
    "'''\n",
    "  # beginning of sample is 2015\n",
    "  first_date = datetime.datetime(year = 2015, month = 4, day = 1)\n",
    "  # When date reaches last date, date resets to first_date (plus one year)\n",
    "  last_date = datetime.datetime(year = 2015, month = 10, day = 3)\n",
    "  date = datetime.datetime(year = 2015, month = 4, day = 1)\n",
    "  # collects team hitting stats for each day\n",
    "  hit = pd.DataFrame()\n",
    "  # collects team pitching stats for each day\n",
    "  pit = pd.DataFrame()\n",
    "  # sustainable way of changing year without change in code\n",
    "  while (date < datetime.datetime.now()):\n",
    "      date_str = date_to_str(date)\n",
    "      # scrape hitting data\n",
    "      hit_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={date.year}&month=1000&season1={date.year}&ind=0&team=0%2Cts&rost=0&age=0&filter=&players=0&startdate={date_str}&enddate={date_str}')\n",
    "      # getting rid of the final row with non-numeric data\n",
    "      hit_df = hit_df[16][:-1]\n",
    "      hit_df[('temp', 'Date')] = date_str\n",
    "      hit_df.columns = hit_df.columns.droplevel(0)\n",
    "      if len(hit_df['#']) > 1:\n",
    "        hit = hit.append(hit_df)\n",
    "      # scrape pitching data\n",
    "      pit_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={date.year}&month=1000&season1={date.year}&ind=0&team=0%2Cts&rost=0&age=0&filter=&players=0&startdate={date_str}&enddate={date_str}')\n",
    "      # getting rid of the final row with non-numeric data\n",
    "      pit_df = pit_df[16][:-1]\n",
    "      pit_df[('temp', 'Date')] = date_str\n",
    "      pit_df.columns = pit_df.columns.droplevel(0)\n",
    "      if len(pit_df['#']) > 1:\n",
    "        pit = pit.append(pit_df)\n",
    "      if (date < last_date):\n",
    "        date += datetime.timedelta(days = 1)\n",
    "      else:\n",
    "        print(date.year)\n",
    "        last_date = datetime.datetime(year = last_date.year + 1, month = last_date.month, day = last_date.day)\n",
    "        first_date = datetime.datetime(year = first_date.year + 1, month = first_date.month, day = first_date.day)\n",
    "        date = first_date\n",
    "  return hit, pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "S2kECEvSQZDs"
   },
   "outputs": [],
   "source": [
    "# CODE USED FOR INITIAL SCRAPING\n",
    "\n",
    "# hit, pit = collect_team_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K-E-H1tkuibp"
   },
   "outputs": [],
   "source": [
    "def collect_new_team_data(df):\n",
    "    '''\n",
    "    Scrapes FanGraphs data from each day the most recent record scraped and today's date\n",
    "\n",
    "    Returns:\n",
    "        hit (pd.DataFrame) contains hitting stats with each record representing one game for a team\n",
    "        pit (pd.DataFrame) contains pitching stats with each record representing one game for a team\n",
    "    '''\n",
    "    recent_record = datetime.datetime.strptime(df['Date'].max(), '%Y-%m-%d')\n",
    "    # beginning of sample is the most recent day data was collected\n",
    "    date = recent_record + datetime.timedelta(days = 1)\n",
    "    # collects team hitting stats for each day\n",
    "    hit = pd.DataFrame()\n",
    "    # collects team pitching stats for each day\n",
    "    pit = pd.DataFrame()\n",
    "    # sustainable way of changing year without change in code\n",
    "    while (date < datetime.datetime.now()):\n",
    "        date_str = date_to_str(date)\n",
    "        # scrape hitting data\n",
    "        hit_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={date.year}&month=1000&season1={date.year}&ind=0&team=0%2Cts&rost=0&age=0&filter=&players=0&startdate={date_str}&enddate={date_str}')\n",
    "        # getting rid of the final row with non-numeric data\n",
    "        hit_df = hit_df[16][:-1]\n",
    "        hit_df[('temp', 'Date')] = date_str\n",
    "        hit_df.columns = hit_df.columns.droplevel(0)\n",
    "        if len(hit_df['#']) > 1:\n",
    "            hit = hit.append(hit_df)\n",
    "        # scrape pitching data\n",
    "        pit_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={date.year}&month=1000&season1={date.year}&ind=0&team=0%2Cts&rost=0&age=0&filter=&players=0&startdate={date_str}&enddate={date_str}')\n",
    "        # getting rid of the final row with non-numeric data\n",
    "        pit_df = pit_df[16][:-1]\n",
    "        pit_df[('temp', 'Date')] = date_str\n",
    "        pit_df.columns = pit_df.columns.droplevel(0)\n",
    "        if len(pit_df['#']) > 1:\n",
    "            pit = pit.append(pit_df)\n",
    "        date += datetime.timedelta(days = 1)\n",
    "    return hit, pit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RCihEEtki5KZ"
   },
   "outputs": [],
   "source": [
    "#CODE USED FOR INITIAL SCRAPING\n",
    "\n",
    "# pit.drop(columns = ['G'], inplace = True)\n",
    "# # Joining hitting and pitching dataframes on team and date\n",
    "# all_stats = pd.merge(hit, pit, left_on = ['Team', 'Date'], right_on = ['Team', 'Date'], how = 'inner')\n",
    "# # Excludes data from days where team played a double header\n",
    "# all_stats = all_stats[all_stats.GS == '1']\n",
    "# all_stats.to_csv('daily_game_stats.csv') \n",
    "# files.download('daily_game_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "XWBVw6pst301",
    "outputId": "37bd5f00-36a2-49ca-9e1f-891c71dbb916"
   },
   "outputs": [],
   "source": [
    "# import MySQLdb\n",
    "# db = MySQLdb.connect(\"localhost\", 'root', 'P@ssw0rd', 'mlb_db')\n",
    "# tblchk = db.cursor()\n",
    "\n",
    "# #CREATING TABLE\n",
    "# tblchk.execute('Drop table if exists game_data')\n",
    "# sql_query = '''create table game_data(gm_id int auto_increment primary key, Team varchar(255), G varchar(255), PA varchar(255), HR varchar(255), R varchar(255), RBI varchar(255), SB varchar(255),\n",
    "#  BB_pct varchar(255), K_pct varchar(255), ISO varchar(255), BABIP_x varchar(255), AVG varchar(255), OBP varchar(255), SLG varchar(255), wOBA varchar(255), xwOBA varchar(255), wRC_plus varchar(255), \n",
    "#  BsR varchar(255), Off varchar(255), Def varchar(255), WAR_x varchar(255), Date varchar(255), W varchar(255), L varchar(255), SV varchar(255), GS varchar(255), \n",
    "#  IP varchar(255), K_per_9 varchar(255), BB_per_9 varchar(255), HR_per_9 varchar(255), BABIP_y varchar(255), LOB_pct varchar(255), GB_pct varchar(255), HR_per_FB varchar(255), vFA varchar(255), \n",
    "#  ERA varchar(255), xERA varchar(255), FIP varchar(255), xFIP varchar(255), WAR_y varchar(255))'''\n",
    "# tblchk.execute(sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method of adding to SQL game_data Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# create sqlalchemy engine\n",
    "engine = create_engine(\"mysql+pymysql://root:P@ssw0rd@localhost/mlb_db\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"P@ssw0rd\",\n",
    "                               db=\"mlb_db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE FOR ADDING INITIAL DATA PREVIOUSLY SCRAPED\n",
    "\n",
    "# new_stats = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/a3774339cb04887ba2026cab07c2923b27422b60/daily_stats%20(2).csv?raw=true', header = 0, index_col = 0)\n",
    "# new_stats.rename(columns = sql_col_mapping, inplace=True)\n",
    "# new_stats.fillna('NA', inplace = True)\n",
    "# #Dropping #_x, #_y\n",
    "# new_stats.drop(columns = ['#_x', '#_y'], inplace = True)\n",
    "# # Insert whole DataFrame into MySQL\n",
    "# new_stats.to_sql('game_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing column names of python df to be able to insert into SQL smoothly\n",
    "sql_col_mapping = {'BB%': 'BB_pct', 'K%': 'K_pct', 'wRC+': 'wRC_plus', 'K/9': 'K_per_9',\n",
    "       'BB/9': 'BB_per_9', 'HR/9': 'HR_per_9', 'LOB%': 'LOB_pct', 'GB%': 'GB_pct', 'HR/FB': 'HR_per_FB', 'vFA (pi)': 'vFA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To change column names of SQL Table for agreement with Python\n",
    "python_col_mapping = {v: k for k, v in sql_col_mapping.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "X9Kgt70JsF_0"
   },
   "outputs": [],
   "source": [
    "def update_game_data(sql_col_mapping):\n",
    "    db = MySQLdb.connect(\"localhost\", 'root', 'P@ssw0rd', 'mlb_db')\n",
    "    # Need to load in CSV identify the most recent date, scrape from most recent date to today, append\n",
    "    game_data = pd.read_sql('SELECT * FROM game_data', con = db)\n",
    "    hit, pit = collect_new_team_data(game_data)\n",
    "    if len(pit) > 0:\n",
    "        pit.drop(columns = ['G'], inplace = True)\n",
    "        # Joining hitting and pitching dataframes on team and date\n",
    "        new_stats = pd.merge(hit, pit, left_on = ['Team', 'Date'], right_on = ['Team', 'Date'], how = 'inner')\n",
    "        new_stats.rename(columns = sql_col_mapping, inplace=True)\n",
    "        new_stats.fillna('NA', inplace = True)\n",
    "        #Dropping #_x, #_y\n",
    "        new_stats.drop(columns = ['#_x', '#_y'], inplace = True)\n",
    "        # Insert whole DataFrame into MySQL\n",
    "        new_stats.to_sql('game_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update_game_data(sql_col_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a string with SQL table columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6dnlwOUKKmV"
   },
   "source": [
    "# Scraping Player Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qz2NsJV8KKmV",
    "outputId": "47c5495b-c9e8-4067-f105-a4e67b6eb17f"
   },
   "outputs": [],
   "source": [
    "def scrape_player_data():\n",
    "    # beginning of sample is 1900\n",
    "    year = 1900\n",
    "    wrc = pd.DataFrame()\n",
    "    pitch = pd.DataFrame()\n",
    "    field = pd.DataFrame()\n",
    "    # sustainable way of changing year without change in code\n",
    "    while year < datetime.datetime.now().year + 1:\n",
    "        for num in range(int(pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page=1_50')[16].columns[0][0][-8:-6].strip())):\n",
    "            # scrape hitting data\n",
    "            if (num < 1):\n",
    "                temp = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page={str(num + 1)}_50')[16][:-1]   \n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                wrc_df = temp\n",
    "            else:\n",
    "                temp = (pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page={str(num + 1)}_50')[16][:-1])\n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                wrc_df = wrc_df.append(temp)\n",
    "            # getting rid of the final row with non-numeric data above\n",
    "        wrc_df['Season'] = year\n",
    "        wrc = wrc.append(wrc_df)\n",
    "        # scrape pitching data\n",
    "        for num in range(int(pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page=1_50')[16].columns[0][0][-8:-6].strip())):\n",
    "            # scrape hitting data\n",
    "            if (num < 1):\n",
    "                temp = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page={str(num + 1)}_50')[16][:-1]   \n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                pitch_df = temp\n",
    "            else:\n",
    "                temp = (pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page={str(num + 1)}_50')[16][:-1])\n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                pitch_df = pitch_df.append(temp)\n",
    "\n",
    "            # getting rid of the final row with non-numeric data above\n",
    "        pitch_df['Season'] = year\n",
    "        pitch = pitch.append(pitch_df)\n",
    "        year+=1\n",
    "    return wrc, pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hKSDyzgnKKmW"
   },
   "outputs": [],
   "source": [
    "def string_to_num(string):\n",
    "    if(type(string) == str):\n",
    "        if('%' in string):\n",
    "            string = string.replace('%', '')\n",
    "    return float(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WGbApoZYhVnH"
   },
   "outputs": [],
   "source": [
    "def clean_player_data(hit_df, pitch_df):\n",
    "    '''\n",
    "    function intended to make statistics numerical, manually calculate statistics, and set the indices to Name and Season\n",
    "\n",
    "    Args:\n",
    "    wrc (pd.DataFrame) contains individual player data by season\n",
    "    pitch (pd.DataFrame) contains individual pitcher data by season\n",
    "\n",
    "    Returns wrc, pitch as clean datasets for use in App'''\n",
    "\n",
    "    # applying the function to each column to ensure all data points are numerical\n",
    "    for col in hit_df.columns:\n",
    "        if col not in ['Name', 'Team', 'Season', 'GB', 'Pos']:\n",
    "            hit_df[col] = hit_df[col].apply(string_to_num)\n",
    "    for col in pitch_df.columns:\n",
    "        if col not in ['Name', 'Team', 'Season', 'GB']:\n",
    "            pitch_df[col] = pitch_df[col].apply(string_to_num)\n",
    "    #Determining home runs allowed for each player for easier calculation\n",
    "    pitch_df['HR'] = pitch_df['HR/9'] * pitch_df['IP'] * 9\n",
    "    #Determining total bases for each player for more accurate slugging percentage calculation\n",
    "    # First must find at bats by subtracting walks using walk percentage\n",
    "    # Calculation ignores HBP\n",
    "    hit_df['AB'] = hit_df['PA'] * (1 - (hit_df['BB%'] * .01))\n",
    "    # Calculation necessary for determining slugging percentage over multiple seasons\n",
    "    hit_df['TB'] = hit_df['SLG'] * hit_df['AB']\n",
    "    pitch_df.set_index(['Name', 'Season'], inplace = True)\n",
    "    hit_df.set_index(['Name', 'Season'], inplace = True)\n",
    "    print(pitch_df.columns)\n",
    "    print(hit_df.columns)\n",
    "    return hit_df, pitch_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ssy5xtSGng3X"
   },
   "outputs": [],
   "source": [
    "def add_new_player_data(hit_df, pit_df):\n",
    "    # Setting up current CSV data to be appended to\n",
    "    year = int(hit_df['Season'].max())\n",
    "    # Excluding current year for freshly scraped aggregates\n",
    "    wrc = pd.DataFrame()\n",
    "    pitch = pd.DataFrame()\n",
    "\n",
    "    while year <= datetime.datetime.now().year:\n",
    "        for num in range(int(pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page=1_50')[16].columns[0][0][-8:-6].strip())):\n",
    "            # scrape hitting data\n",
    "            if (num < 1):\n",
    "                temp = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page={str(num + 1)}_50')[16][:-1]   \n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                wrc_df = temp\n",
    "            else:\n",
    "                temp = (pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate=&enddate=&page={str(num + 1)}_50')[16][:-1])\n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                wrc_df = wrc_df.append(temp)\n",
    "            # getting rid of the final row with non-numeric data above\n",
    "        wrc_df['Season'] = year\n",
    "        wrc = wrc.append(wrc_df)\n",
    "        # scrape pitching data\n",
    "        for num in range(int(pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page=1_50')[16].columns[0][0][-8:-6].strip())):\n",
    "            # scrape hitting data\n",
    "            if (num < 1):\n",
    "                temp = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page={str(num + 1)}_50')[16][:-1]   \n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                pitch_df = temp\n",
    "            else:\n",
    "                temp = (pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0&rost=0&age=0&filter=&players=0&startdate={year}-01-01&enddate={year}-12-31&sort=21,d&page={str(num + 1)}_50')[16][:-1])\n",
    "                temp.columns = temp.columns.droplevel(0)\n",
    "                pitch_df = pitch_df.append(temp)\n",
    "            # getting rid of the final row with non-numeric data above\n",
    "        pitch_df['Season'] = year\n",
    "        pitch = pitch.append(pitch_df)\n",
    "        year+=1\n",
    "    hit_df, pitch_df = clean_player_data(wrc, pitch)\n",
    "    return hit_df, pitch_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "fJTvg0ujlIjt",
    "outputId": "77311a29-e5db-4baf-ae31-fb325463450e"
   },
   "outputs": [],
   "source": [
    "# CODE FROM INITIAL SCRAPING\n",
    "\n",
    "# hit_df.to_csv('hitters_yearly.csv') \n",
    "# pitch_df.to_csv('pitchers_yearly.csv')\n",
    "# files.download('hitters_yearly.csv')\n",
    "# files.download('pitchers_yearly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hit_df = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/5548a60b92575ee19b159c791934630cbd9f72d3/hitters_yearly.csv?raw=true', header = 0)\n",
    "# pitch_df = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/5548a60b92575ee19b159c791934630cbd9f72d3/pitchers_yearly.csv?raw=true', header = 0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading player data from CSVs into SQL Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import MySQLdb\n",
    "# db = MySQLdb.connect(\"localhost\", 'root', 'P@ssw0rd', 'mlb_db')\n",
    "# tblchk = db.cursor()\n",
    "\n",
    "# #CREATING HITTER TABLE\n",
    "# tblchk.execute('Drop table if exists hitter_data')\n",
    "# sql_query = '''create table hitter_data(hitter_id int auto_increment primary key, Name varchar(255), Season varchar(255),\n",
    "# Team varchar(255), G varchar(255), PA varchar(255), HR varchar(255), R varchar(255), RBI varchar(255), \n",
    "# SB varchar(255), BB_pct varchar(255), K_pct varchar(255), ISO varchar(255), BABIP varchar(255), AVG varchar(255),\n",
    "# OBP varchar(255), SLG varchar(255), wOBA varchar(255), xwOBA varchar(255), wRC_plus varchar(255), BsR varchar(255), \n",
    "# Off varchar(255), Def varchar(255), WAR varchar(255), AB varchar(255), TB varchar(255))'''\n",
    "# tblchk.execute(sql_query)\n",
    "\n",
    "# #CREATING PITCHER TABLE\n",
    "# tblchk.execute('Drop table if exists pitcher_data')\n",
    "# sql_query = '''create table pitcher_data(pitcher_id int auto_increment primary key, Name varchar(255),\n",
    "# Season varchar(255), Team varchar(255), W varchar(255), L varchar(255), SV varchar(255), \n",
    "# G varchar(255), GS varchar(255), IP varchar(255), K_per_9 varchar(255), BB_per_9 varchar(255), HR_per_9 varchar(255), \n",
    "# BABIP varchar(255), LOB_pct varchar(255), GB_pct varchar(255), HR_per_FB varchar(255), vFA varchar(255), \n",
    "# ERA varchar(255), xERA varchar(255), FIP varchar(255), xFIP varchar(255), WAR varchar(255), HR varchar(255))'''\n",
    "# tblchk.execute(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CODE FOR ADDING INITIAL DATA PREVIOUSLY SCRAPED\n",
    "# engine = create_engine(\"mysql+pymysql://root:P@ssw0rd@localhost/mlb_db\"\n",
    "#                        .format(user=\"root\",\n",
    "#                                pw=\"P@ssw0rd\",\n",
    "#                                db=\"mlb_db\"))\n",
    "# new_hit_df = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/5548a60b92575ee19b159c791934630cbd9f72d3/hitters_yearly.csv?raw=true', header = 0)\n",
    "# new_hit_df.rename(columns = sql_col_mapping, inplace=True)\n",
    "# new_hit_df.fillna('NA', inplace = True)\n",
    "# #Dropping #\n",
    "# new_hit_df.drop(columns = ['#'], inplace = True)\n",
    "# # Insert whole DataFrame into MySQL\n",
    "# new_hit_df.to_sql('hitter_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #CODE FOR ADDING INITIAL DATA PREVIOUSLY SCRAPED\n",
    "# engine = create_engine(\"mysql+pymysql://root:P@ssw0rd@localhost/mlb_db\"\n",
    "#                        .format(user=\"root\",\n",
    "#                                pw=\"P@ssw0rd\",\n",
    "#                                db=\"mlb_db\"))\n",
    "# new_pit_df = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/5548a60b92575ee19b159c791934630cbd9f72d3/pitchers_yearly.csv?raw=true', header = 0)\n",
    "# new_pit_df.rename(columns = sql_col_mapping, inplace=True)\n",
    "# new_pit_df.fillna('NA', inplace = True)\n",
    "# #Dropping #\n",
    "# new_pit_df.drop(columns = ['#'], inplace = True)\n",
    "# # Insert whole DataFrame into MySQL\n",
    "# new_pit_df.to_sql('pitcher_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "DCEK6hfTtUCz",
    "outputId": "8bef80b6-2c79-4675-b49c-08e5db131437"
   },
   "outputs": [],
   "source": [
    "def update_players_data(sql_col_mapping):\n",
    "    db = MySQLdb.connect(\"localhost\", 'root', 'P@ssw0rd', 'mlb_db')\n",
    "    tblchk = db.cursor()\n",
    "    hit_df_ = pd.read_sql('SELECT * FROM hitter_data', con = db)\n",
    "    pit_df_ = pd.read_sql('SELECT * FROM pitcher_data', con = db)\n",
    "    hit, pit = add_new_player_data(hit_df_, pit_df_)\n",
    "    if len(pit) > 0:\n",
    "        pit.drop(columns = ['G'], inplace = True)\n",
    "        # Joining hitting and pitching dataframes on team and date\n",
    "        hit.rename(columns = sql_col_mapping, inplace=True)\n",
    "        pit.rename(columns = sql_col_mapping, inplace=True)\n",
    "        hit.fillna('NA', inplace = True)\n",
    "        pit.fillna('NA', inplace = True)\n",
    "        # resetting the indices\n",
    "        hit.reset_index(inplace = True)\n",
    "        pit.reset_index(inplace = True)\n",
    "        # Dropping #_x, #_y\n",
    "        hit.drop(columns = ['#'], inplace = True)\n",
    "        pit.drop(columns = ['#'], inplace = True)\n",
    "        # deleting current year records\n",
    "        max_year = hit['Season'].max()\n",
    "        sql_query = f'''DELETE FROM hitter_data hd \n",
    "                        WHERE hd.Season >= {max_year};\n",
    "                        COMMIT;'''\n",
    "        tblchk.execute(sql_query)\n",
    "        sql_query = f'''DELETE FROM pitcher_data pd \n",
    "                        WHERE pd.Season >= {max_year};\n",
    "                        COMMIT;'''\n",
    "        tblchk.execute(sql_query)\n",
    "        engine = create_engine(\"mysql+pymysql://root:P@ssw0rd@localhost/mlb_db\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"P@ssw0rd\",\n",
    "                               db=\"mlb_db\"))\n",
    "        # adding data from newest year\n",
    "        hit.to_sql('hitter_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)\n",
    "        pit.to_sql('pitcher_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022\n",
      "2022\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "herb\n",
      "Index(['#', 'Team', 'W', 'L', 'SV', 'G', 'GS', 'IP', 'K/9', 'BB/9', 'HR/9',\n",
      "       'BABIP', 'LOB%', 'GB%', 'HR/FB', 'vFA (pi)', 'ERA', 'xERA', 'FIP',\n",
      "       'xFIP', 'WAR', 'HR'],\n",
      "      dtype='object')\n",
      "Index(['#', 'Team', 'G', 'PA', 'HR', 'R', 'RBI', 'SB', 'BB%', 'K%', 'ISO',\n",
      "       'BABIP', 'AVG', 'OBP', 'SLG', 'wOBA', 'xwOBA', 'wRC+', 'BsR', 'Off',\n",
      "       'Def', 'WAR', 'AB', 'TB'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "update_players_data(sql_col_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11wJoCATbjSJ"
   },
   "source": [
    "# Collecting team data to compare model predictions to actual full season win totals\n",
    "\n",
    "- key question is what model or combination of models minimizes error in predicting team success historically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import MySQLdb\n",
    "# db = MySQLdb.connect(\"localhost\", 'root', 'P@ssw0rd', 'mlb_db')\n",
    "# tblchk = db.cursor()\n",
    "\n",
    "# #CREATING TEAM DATA TABLE\n",
    "# tblchk.execute('Drop table if exists team_data')\n",
    "# sql_query = '''create table team_data(team_id int auto_increment primary key, Team varchar(255), G_x varchar(255),\n",
    "# PA varchar(255), HR varchar(255), R varchar(255), RBI varchar(255), SB varchar(255), BB_pct varchar(255), \n",
    "# K_pct varchar(255), ISO varchar(255), BABIP_x varchar(255), AVG varchar(255), OBP varchar(255), SLG varchar(255),\n",
    "# wOBA varchar(255), xwOBA varchar(255), wRC_plus varchar(255), BsR varchar(255), Off varchar(255), Def varchar(255),\n",
    "# WAR_x varchar(255), Season varchar(255), W varchar(255), L varchar(255), SV varchar(255),\n",
    "# G_y varchar(255), GS varchar(255), IP varchar(255), K_per_9 varchar(255), BB_per_9 varchar(255), HR_per_9 varchar(255),\n",
    "# BABIP_y varchar(255), LOB_pct varchar(255), GB_pct varchar(255), HR_per_FB varchar(255), vFA varchar(255),\n",
    "# ERA varchar(255), xERA varchar(255), FIP varchar(255), xFIP varchar(255), WAR_y varchar(255))'''\n",
    "# tblchk.execute(sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE FOR ADDING INITIAL DATA PREVIOUSLY SCRAPED\n",
    "\n",
    "# team_data = pd.read_csv('https://github.com/timseymour42/MLB-Build-a-Team/blob/8d552de89f4daf8a9aa27edde95179f3bb192258/team_yearly_data.csv?raw=true', header = 0)\n",
    "# team_data.rename(columns = sql_col_mapping, inplace=True)\n",
    "# team_data.fillna('NA', inplace = True)\n",
    "# #Dropping unnecessary columns\n",
    "# print(team_data.columns)\n",
    "# team_data.drop(columns = ['#_x', '#_y', 'Unnamed: 0'], inplace = True)\n",
    "# # Insert whole DataFrame into MySQL\n",
    "# team_data.to_sql('team_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89PrPt2MKKmJ",
    "outputId": "e2ce249e-e376-41bf-b71f-898deae1b46d"
   },
   "outputs": [],
   "source": [
    "def collect_team_data_yearly(year):\n",
    "\n",
    "    '''\n",
    "    Args:\n",
    "    year (integer): year to start collecting data from\n",
    "    Collecting team data to use as testing data\n",
    "    '''\n",
    "    year = int(year)\n",
    "    wrc = pd.DataFrame()\n",
    "    pitch = pd.DataFrame()\n",
    "    field = pd.DataFrame()\n",
    "    # sustainable way of changing year without change in code\n",
    "    while year < datetime.datetime.now().year + 1:\n",
    "        # scrape hitting data\n",
    "        wrc_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=bat&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0,ts&rost=0&age=0&filter=&players=0&startdate=&enddate=')\n",
    "        # getting rid of the final row with non-numeric data\n",
    "        wrc_df = wrc_df[16][:-1]\n",
    "        wrc_df[('temp', 'Season')] = year\n",
    "        wrc_df.columns = wrc_df.columns.droplevel(0)\n",
    "        wrc = pd.concat([wrc, wrc_df], axis = 0)\n",
    "        # scrape pitching data\n",
    "        pitch_df = pd.read_html(f'https://www.fangraphs.com/leaders.aspx?pos=all&stats=pit&lg=all&qual=0&type=8&season={year}&month=0&season1={year}&ind=0&team=0,ts&rost=0&age=0&filter=&players=0&startdate=&enddate=')\n",
    "        # getting rid of the final row with non-numeric data\n",
    "        pitch_df = pitch_df[16][:-1]\n",
    "        pitch_df[('temp', 'Season')] = year\n",
    "        pitch_df.columns = pitch_df.columns.droplevel(0)\n",
    "        pitch = pd.concat([pitch, pitch_df], axis = 0)\n",
    "        year += 1\n",
    "    return wrc, pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "EXQ6c_rBmuCC",
    "outputId": "af9ea4d3-e66e-4f6e-8f6d-872ec4d0ebee",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_04fd70ba-b41a-4c5b-8caf-834c696616ea\", \"team_yearly_data.csv\", 579634)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CODE USED FOR INITIAL SCRAPING\n",
    "\n",
    "# team_data.to_csv('team_yearly_data.csv')\n",
    "# files.download('team_yearly_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_team_data = pd.read_sql('SELECT * FROM team_data', con = db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>team_id</th>\n",
       "      <th>Team</th>\n",
       "      <th>G_x</th>\n",
       "      <th>PA</th>\n",
       "      <th>HR</th>\n",
       "      <th>R</th>\n",
       "      <th>RBI</th>\n",
       "      <th>SB</th>\n",
       "      <th>BB_pct</th>\n",
       "      <th>K_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>BABIP_y</th>\n",
       "      <th>LOB_pct</th>\n",
       "      <th>GB_pct</th>\n",
       "      <th>HR_per_FB</th>\n",
       "      <th>vFA</th>\n",
       "      <th>ERA</th>\n",
       "      <th>xERA</th>\n",
       "      <th>FIP</th>\n",
       "      <th>xFIP</th>\n",
       "      <th>WAR_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>BRO</td>\n",
       "      <td>1354</td>\n",
       "      <td>5440</td>\n",
       "      <td>26</td>\n",
       "      <td>816</td>\n",
       "      <td>676</td>\n",
       "      <td>274</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298</td>\n",
       "      <td>62.3</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.89</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.65</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>STL</td>\n",
       "      <td>1352</td>\n",
       "      <td>5444</td>\n",
       "      <td>36</td>\n",
       "      <td>744</td>\n",
       "      <td>602</td>\n",
       "      <td>243</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.301</td>\n",
       "      <td>58.1</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.76</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.43</td>\n",
       "      <td>NA</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1337</td>\n",
       "      <td>5594</td>\n",
       "      <td>29</td>\n",
       "      <td>810</td>\n",
       "      <td>694</td>\n",
       "      <td>205</td>\n",
       "      <td>7.9</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313</td>\n",
       "      <td>61.2</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.13</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.64</td>\n",
       "      <td>NA</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>BSN</td>\n",
       "      <td>1382</td>\n",
       "      <td>5499</td>\n",
       "      <td>48</td>\n",
       "      <td>778</td>\n",
       "      <td>676</td>\n",
       "      <td>182</td>\n",
       "      <td>7.2</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276</td>\n",
       "      <td>61.3</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.72</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1349</td>\n",
       "      <td>5317</td>\n",
       "      <td>26</td>\n",
       "      <td>733</td>\n",
       "      <td>602</td>\n",
       "      <td>174</td>\n",
       "      <td>6.2</td>\n",
       "      <td>NA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284</td>\n",
       "      <td>62.9</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.06</td>\n",
       "      <td>NA</td>\n",
       "      <td>3.13</td>\n",
       "      <td>NA</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>2576</td>\n",
       "      <td>BAL</td>\n",
       "      <td>906</td>\n",
       "      <td>2242</td>\n",
       "      <td>77</td>\n",
       "      <td>274</td>\n",
       "      <td>264</td>\n",
       "      <td>19</td>\n",
       "      <td>7.3</td>\n",
       "      <td>22.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282</td>\n",
       "      <td>69.7</td>\n",
       "      <td>42.6</td>\n",
       "      <td>14.6</td>\n",
       "      <td>92.8</td>\n",
       "      <td>4.51</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.63</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>2577</td>\n",
       "      <td>MIA</td>\n",
       "      <td>904</td>\n",
       "      <td>2167</td>\n",
       "      <td>60</td>\n",
       "      <td>263</td>\n",
       "      <td>247</td>\n",
       "      <td>51</td>\n",
       "      <td>8.8</td>\n",
       "      <td>24.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297</td>\n",
       "      <td>70.6</td>\n",
       "      <td>45.2</td>\n",
       "      <td>15.7</td>\n",
       "      <td>92.5</td>\n",
       "      <td>4.86</td>\n",
       "      <td>NA</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>2578</td>\n",
       "      <td>COL</td>\n",
       "      <td>888</td>\n",
       "      <td>2257</td>\n",
       "      <td>63</td>\n",
       "      <td>275</td>\n",
       "      <td>264</td>\n",
       "      <td>42</td>\n",
       "      <td>7.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307</td>\n",
       "      <td>66.5</td>\n",
       "      <td>44.5</td>\n",
       "      <td>15</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.59</td>\n",
       "      <td>NA</td>\n",
       "      <td>5.14</td>\n",
       "      <td>5.13</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>2579</td>\n",
       "      <td>PIT</td>\n",
       "      <td>873</td>\n",
       "      <td>2134</td>\n",
       "      <td>59</td>\n",
       "      <td>219</td>\n",
       "      <td>210</td>\n",
       "      <td>16</td>\n",
       "      <td>7.8</td>\n",
       "      <td>24.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.28</td>\n",
       "      <td>70.2</td>\n",
       "      <td>43.4</td>\n",
       "      <td>16.2</td>\n",
       "      <td>93.2</td>\n",
       "      <td>4.68</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.63</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>2580</td>\n",
       "      <td>TEX</td>\n",
       "      <td>865</td>\n",
       "      <td>2147</td>\n",
       "      <td>62</td>\n",
       "      <td>224</td>\n",
       "      <td>204</td>\n",
       "      <td>49</td>\n",
       "      <td>7.8</td>\n",
       "      <td>25.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.27699999999999997</td>\n",
       "      <td>68.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>14</td>\n",
       "      <td>93.2</td>\n",
       "      <td>5.02</td>\n",
       "      <td>NA</td>\n",
       "      <td>4.88</td>\n",
       "      <td>5</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2580 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      team_id Team   G_x    PA  HR    R  RBI   SB BB_pct K_pct  ...  \\\n",
       "0           1  BRO  1354  5440  26  816  676  274    7.7    NA  ...   \n",
       "1           2  STL  1352  5444  36  744  602  243    7.5    NA  ...   \n",
       "2           3  PHI  1337  5594  29  810  694  205    7.9    NA  ...   \n",
       "3           4  BSN  1382  5499  48  778  676  182    7.2    NA  ...   \n",
       "4           5  PIT  1349  5317  26  733  602  174    6.2    NA  ...   \n",
       "...       ...  ...   ...   ...  ..  ...  ...  ...    ...   ...  ...   \n",
       "2575     2576  BAL   906  2242  77  274  264   19    7.3  22.9  ...   \n",
       "2576     2577  MIA   904  2167  60  263  247   51    8.8  24.8  ...   \n",
       "2577     2578  COL   888  2257  63  275  264   42    7.1  24.1  ...   \n",
       "2578     2579  PIT   873  2134  59  219  210   16    7.8  24.4  ...   \n",
       "2579     2580  TEX   865  2147  62  224  204   49    7.8  25.5  ...   \n",
       "\n",
       "                  BABIP_y LOB_pct GB_pct HR_per_FB   vFA   ERA xERA   FIP  \\\n",
       "0                   0.298    62.3     NA        NA    NA  3.89   NA  3.65   \n",
       "1                   0.301    58.1     NA        NA    NA  3.76   NA  3.43   \n",
       "2                   0.313    61.2     NA        NA    NA  4.13   NA  3.64   \n",
       "3                   0.276    61.3     NA        NA    NA  3.72   NA  4.02   \n",
       "4                   0.284    62.9     NA        NA    NA  3.06   NA  3.13   \n",
       "...                   ...     ...    ...       ...   ...   ...  ...   ...   \n",
       "2575                0.282    69.7   42.6      14.6  92.8  4.51   NA   4.6   \n",
       "2576                0.297    70.6   45.2      15.7  92.5  4.86   NA  5.02   \n",
       "2577                0.307    66.5   44.5        15  94.3  5.59   NA  5.14   \n",
       "2578                 0.28    70.2   43.4      16.2  93.2  4.68   NA   4.8   \n",
       "2579  0.27699999999999997    68.6   40.6        14  93.2  5.02   NA  4.88   \n",
       "\n",
       "      xFIP WAR_y  \n",
       "0       NA  10.7  \n",
       "1       NA  14.5  \n",
       "2       NA  10.3  \n",
       "3       NA   9.8  \n",
       "4       NA  16.4  \n",
       "...    ...   ...  \n",
       "2575  4.63   6.5  \n",
       "2576   4.9   2.2  \n",
       "2577  5.13   3.3  \n",
       "2578  4.63   2.7  \n",
       "2579     5   2.6  \n",
       "\n",
       "[2580 rows x 42 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_team_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       W     GS\n",
      "0   35.0   60.0\n",
      "1   37.0   60.0\n",
      "2   43.0   60.0\n",
      "3   35.0   60.0\n",
      "4   26.0   60.0\n",
      "..   ...    ...\n",
      "85  56.0  154.0\n",
      "86  53.0  154.0\n",
      "87  60.0  155.0\n",
      "88  58.0  155.0\n",
      "89  61.0  153.0\n",
      "\n",
      "[90 rows x 2 columns]\n",
      "0      94.500000\n",
      "1      99.900000\n",
      "2     116.100000\n",
      "3      94.500000\n",
      "4      70.200000\n",
      "         ...    \n",
      "85     58.909091\n",
      "86     55.753247\n",
      "87     62.709677\n",
      "88     60.619355\n",
      "89     64.588235\n",
      "Name: W, Length: 90, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "update_team_data(sql_col_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Ze2euU7suYBG"
   },
   "outputs": [],
   "source": [
    "def update_team_data(sql_col_mapping):\n",
    "    db = MySQLdb.connect(\"localhost\", 'root', '', 'mlb_db')\n",
    "    tblchk = db.cursor()\n",
    "    # The year of the latest record in the data table\n",
    "    sql_team_data = pd.read_sql('SELECT * FROM team_data', con = db)\n",
    "    max_year = 2020\n",
    "#     max_year = sql_team_data['Season'].max()\n",
    "#     sql_query = f'''DELETE FROM team_data td \n",
    "#                     WHERE td.Season >= {max_year};\n",
    "                    \n",
    "#                     COMMIT;'''\n",
    "#     tblchk.execute(sql_query)\n",
    "    \n",
    "    #collecting team data from most recent year to the present\n",
    "    h, p = collect_team_data_yearly(max_year)\n",
    "    team_data = pd.merge(h, p, left_on = ['Season', 'Team'], right_on = ['Season', 'Team'], how = 'outer')\n",
    "    for col in team_data.columns:\n",
    "        if col not in ['Team', 'Season', 'GB']:\n",
    "            team_data[col] = team_data[col].apply(string_to_num)\n",
    "    print(team_data[['W', 'GS']])\n",
    "    team_data['W'] = team_data['W'] * (162 / team_data['GS'])\n",
    "    print(team_data['W'])\n",
    "    team_data.rename(columns = sql_col_mapping, inplace=True)\n",
    "    team_data.fillna('NA', inplace = True)\n",
    "    #Dropping unnecessary columns\n",
    "    team_data.drop(columns = ['#_x', '#_y'], inplace = True)\n",
    "#     #Creating engine to append dataframe to database\n",
    "#     engine = create_engine(\"mysql+pymysql://root:P@ssw0rd@localhost/mlb_db\"\n",
    "#                        .format(user=\"root\",\n",
    "#                                pw=\"P@ssw0rd\",\n",
    "#                                db=\"mlb_db\"))\n",
    "#     # adding data from newest year\n",
    "#     team_data.to_sql('team_data', con = engine, if_exists = 'append', chunksize = 1000, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_team_data(sql_col_mapping)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Automated-Data-Collection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
